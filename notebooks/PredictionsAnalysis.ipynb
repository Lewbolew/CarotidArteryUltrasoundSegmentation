{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Challenging patients\n",
    "131283,197476,217636,232742,293936,318984,428903,435714,521105,\n",
    "557910,559832,587463,609078,713916,716744,756515,824987,840313,\n",
    "931912,961520,983053,988464\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMetrics(object):\n",
    "    \"\"\"\n",
    "    Class, which has methods for measuring all basic performance metrics for semantic segmentation:\n",
    "    - Pixel accuracy;\n",
    "    - Mean accuracy;\n",
    "    - Mean IoU;\n",
    "    - frequency_weighted_IU\n",
    "    \n",
    "    Takes collapsed masks as an input(after used np.argmax()), where dimention of the image should be width x heigts and\n",
    "    the set of pixel values from 0 to number of classes. \n",
    "    \"\"\"\n",
    "    def pixel_accuracy(self, eval_segm, gt_segm):\n",
    "        '''\n",
    "        sum_i(n_ii) / sum_i(t_i)\n",
    "        '''\n",
    "\n",
    "        self.check_size(eval_segm, gt_segm)\n",
    "\n",
    "        cl, n_cl = self.extract_classes(gt_segm)\n",
    "        eval_mask, gt_mask = self.extract_both_masks(eval_segm, gt_segm, cl, n_cl)\n",
    "\n",
    "        sum_n_ii = 0\n",
    "        sum_t_i  = 0\n",
    "\n",
    "        for i, c in enumerate(cl):\n",
    "            curr_eval_mask = eval_mask[i, :, :]\n",
    "            curr_gt_mask = gt_mask[i, :, :]\n",
    "\n",
    "            sum_n_ii += np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))\n",
    "            sum_t_i  += np.sum(curr_gt_mask)\n",
    "\n",
    "        if (sum_t_i == 0):\n",
    "            pixel_accuracy_ = 0\n",
    "        else:\n",
    "            pixel_accuracy_ = sum_n_ii / sum_t_i\n",
    "\n",
    "        return pixel_accuracy_\n",
    "\n",
    "    def mean_accuracy(self, eval_segm, gt_segm):\n",
    "        '''\n",
    "        (1/n_cl) sum_i(n_ii/t_i)\n",
    "        '''\n",
    "\n",
    "        self.check_size(eval_segm, gt_segm)\n",
    "\n",
    "        cl, n_cl = self.extract_classes(gt_segm)\n",
    "        eval_mask, gt_mask = self.extract_both_masks(eval_segm, gt_segm, cl, n_cl)\n",
    "\n",
    "        accuracy = list([0]) * n_cl\n",
    "\n",
    "        for i, c in enumerate(cl):\n",
    "            curr_eval_mask = eval_mask[i, :, :]\n",
    "            curr_gt_mask = gt_mask[i, :, :]\n",
    "\n",
    "            n_ii = np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))\n",
    "            t_i  = np.sum(curr_gt_mask)\n",
    "\n",
    "            if (t_i != 0):\n",
    "                accuracy[i] = n_ii / t_i\n",
    "\n",
    "        mean_accuracy_ = np.mean(accuracy)\n",
    "        return mean_accuracy_\n",
    "\n",
    "    def mean_IU(self, eval_segm, gt_segm):\n",
    "        '''\n",
    "        (1/n_cl) * sum_i(n_ii / (t_i + sum_j(n_ji) - n_ii))\n",
    "        '''\n",
    "\n",
    "        self.check_size(eval_segm, gt_segm)\n",
    "\n",
    "        cl, n_cl   = self.union_classes(eval_segm, gt_segm)\n",
    "        _, n_cl_gt = self.extract_classes(gt_segm)\n",
    "        eval_mask, gt_mask = self.extract_both_masks(eval_segm, gt_segm, cl, n_cl)\n",
    "\n",
    "        IU = list([0]) * n_cl\n",
    "\n",
    "        for i, c in enumerate(cl):\n",
    "            curr_eval_mask = eval_mask[i, :, :]\n",
    "            curr_gt_mask = gt_mask[i, :, :]\n",
    "\n",
    "            if (np.sum(curr_eval_mask) == 0) or (np.sum(curr_gt_mask) == 0):\n",
    "                continue\n",
    "\n",
    "            n_ii = np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))\n",
    "            t_i  = np.sum(curr_gt_mask)\n",
    "            n_ij = np.sum(curr_eval_mask)\n",
    "\n",
    "            IU[i] = n_ii / (t_i + n_ij - n_ii)\n",
    "\n",
    "        mean_IU_ = np.sum(IU) / n_cl_gt\n",
    "        return mean_IU_\n",
    "\n",
    "    def frequency_weighted_IU(self, eval_segm, gt_segm):\n",
    "        '''\n",
    "        sum_k(t_k)^(-1) * sum_i((t_i*n_ii)/(t_i + sum_j(n_ji) - n_ii))\n",
    "        '''\n",
    "\n",
    "        self.check_size(eval_segm, gt_segm)\n",
    "\n",
    "        cl, n_cl = self.union_classes(eval_segm, gt_segm)\n",
    "        eval_mask, gt_mask = self.extract_both_masks(eval_segm, gt_segm, cl, n_cl)\n",
    "\n",
    "        frequency_weighted_IU_ = list([0]) * n_cl\n",
    "\n",
    "        for i, c in enumerate(cl):\n",
    "            curr_eval_mask = eval_mask[i, :, :]\n",
    "            curr_gt_mask = gt_mask[i, :, :]\n",
    "\n",
    "            if (np.sum(curr_eval_mask) == 0) or (np.sum(curr_gt_mask) == 0):\n",
    "                continue\n",
    "\n",
    "            n_ii = np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))\n",
    "            t_i  = np.sum(curr_gt_mask)\n",
    "            n_ij = np.sum(curr_eval_mask)\n",
    "\n",
    "            frequency_weighted_IU_[i] = (t_i * n_ii) / (t_i + n_ij - n_ii)\n",
    "\n",
    "        sum_k_t_k = self.get_pixel_area(eval_segm)\n",
    "\n",
    "        frequency_weighted_IU_ = np.sum(frequency_weighted_IU_) / sum_k_t_k\n",
    "        return frequency_weighted_IU_\n",
    "\n",
    "    def get_pixel_area(self, segm):\n",
    "        return segm.shape[0] * segm.shape[1]\n",
    "\n",
    "    def extract_both_masks(self, eval_segm, gt_segm, cl, n_cl):\n",
    "        eval_mask = self.extract_masks(eval_segm, cl, n_cl)\n",
    "        gt_mask   = self.extract_masks(gt_segm, cl, n_cl)\n",
    "\n",
    "        return eval_mask, gt_mask\n",
    "\n",
    "    def extract_classes(self,segm):\n",
    "        cl = np.unique(segm)\n",
    "        n_cl = len(cl)\n",
    "\n",
    "        return cl, n_cl\n",
    "\n",
    "    def union_classes(self, eval_segm, gt_segm):\n",
    "        eval_cl, _ = self.extract_classes(eval_segm)\n",
    "        gt_cl, _   = self.extract_classes(gt_segm)\n",
    "\n",
    "        cl = np.union1d(eval_cl, gt_cl)\n",
    "        n_cl = len(cl)\n",
    "\n",
    "        return cl, n_cl\n",
    "\n",
    "    def extract_masks(self, segm, cl, n_cl):\n",
    "        h, w  = self.segm_size(segm)\n",
    "        masks = np.zeros((n_cl, h, w))\n",
    "\n",
    "        for i, c in enumerate(cl):\n",
    "            masks[i, :, :] = segm == c\n",
    "\n",
    "        return masks\n",
    "\n",
    "    def segm_size(self, segm):\n",
    "        try:\n",
    "            height = segm.shape[0]\n",
    "            width  = segm.shape[1]\n",
    "        except IndexError:\n",
    "            raise\n",
    "\n",
    "        return height, width\n",
    "\n",
    "    def check_size(self, eval_segm, gt_segm):\n",
    "        h_e, w_e = self.segm_size(eval_segm)\n",
    "        h_g, w_g = self.segm_size(gt_segm)\n",
    "\n",
    "        if (h_e != h_g) or (w_e != w_g):\n",
    "            raise EvalSegErr(\"DiffDim: Different dimensions of matrices!\")\n",
    "\n",
    "\n",
    "    class EvalSegErr(Exception):\n",
    "        '''\n",
    "        Class exception \n",
    "        '''\n",
    "        def __init__(self, value):\n",
    "            self.value = value\n",
    "\n",
    "        def __str__(self):\n",
    "            return repr(self.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base class evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEvaluator(object):\n",
    "    \n",
    "    def __init__(self, prediction_dict_path):\n",
    "        self.dict_of_prediction_data = pickle.load(open(prediction_dict_path, \"rb\"))\n",
    "        self.predictions = self.dict_of_prediction_data['predictions']\n",
    "#         self.ground_truth = self.dict_of_prediction_data['y']\n",
    "        self.images = self.dict_of_prediction_data['x']\n",
    "#         self.history_of_training = self.dict_of_prediction_data['history_of_training']\n",
    "        self.number_of_test_images = len(self.predictions)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.number_of_test_images\n",
    "\n",
    "    def display_training_history(self):\n",
    "        \"\"\"\n",
    "        Draw 2 figures(validation and training info) about loss and accuracy. \n",
    "        \"\"\"\n",
    "        loss_hist = [s for s in self.history_of_training.keys() if 'loss' in s and 'val' not in s]\n",
    "        val_loss_list = [s for s in self.history_of_training.keys() if 'loss' in s and 'val' in s]\n",
    "        acc_list = [s for s in self.history_of_training.keys() if 'acc' in s and 'val' not in s]\n",
    "        val_acc_list = [s for s in self.history_of_training.keys() if 'acc' in s and 'val' in s]\n",
    "\n",
    "        if len(loss_hist) == 0:\n",
    "            print('Missing history')\n",
    "            return\n",
    "\n",
    "        epochs = range(1,len(self.history_of_training[loss_hist[0]]) + 1)\n",
    "\n",
    "        # loss\n",
    "        fig = plt.figure(frameon=False)\n",
    "        ax = plt.gca()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        for l in loss_hist:\n",
    "            plt.plot(epochs, \n",
    "                     self.history_of_training[l], \n",
    "                     'b', \n",
    "                     label='Training loss ('+str(str(format(self.history_of_training[l][-1],'.5f'))+')'),\n",
    "                     linewidth=3\n",
    "                    )\n",
    "        for l in val_loss_list:\n",
    "            plt.plot(epochs, \n",
    "                     self.history_of_training[l], \n",
    "                     'g',\n",
    "                     label='Validation loss ('+str(str(format(self.history_of_training[l][-1],'.5f'))+')'),\n",
    "                     linewidth=3\n",
    "                    )\n",
    "        plt.title('Loss', fontsize=50, fontdict={'fontweight':'bold'})\n",
    "        plt.xlabel('Epochs',fontsize=20, fontdict={'fontweight':'bold'})\n",
    "        plt.ylabel('Loss',fontsize=20, fontdict={'fontweight':'bold'})\n",
    "        plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "        plt.grid(b=True)\n",
    "        plt.legend(fontsize=30)\n",
    "\n",
    "        # accuracy\n",
    "        fig1 = plt.figure(frameon=False)\n",
    "        ax1 = plt.gca()\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        for l in acc_list:\n",
    "            plt.plot(epochs, self.history_of_training[l], 'b', \n",
    "                     label='Training accuracy ('+str(format(self.history_of_training[l][-1],'.5f'))+')',\n",
    "                     linewidth=3\n",
    "                    )\n",
    "        for l in val_acc_list:    \n",
    "            plt.plot(epochs, self.history_of_training[l], 'g', \n",
    "                     label='Validation accuracy ('+str(format(self.history_of_training[l][-1],'.5f'))+')',\n",
    "                     linewidth=3\n",
    "                    )\n",
    "\n",
    "        plt.title('Accuracy',fontsize=50, fontdict={'fontweight':'bold'})\n",
    "        plt.xlabel('Epochs',fontsize=20, fontdict={'fontweight':'bold'})\n",
    "        plt.ylabel('Accuracy',fontsize=20, fontdict={'fontweight':'bold'})\n",
    "        plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "        plt.grid(b=True)\n",
    "\n",
    "        plt.legend(loc=4, fontsize=30)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidEvaluator(BaseEvaluator):\n",
    "    \n",
    "    def __init__(self, prediction_dict_path, best_threshold=0.5):\n",
    "        BaseEvaluator.__init__(self,prediction_dict_path)\n",
    "        self.best_threshold = best_threshold\n",
    "\n",
    "    def threshold(self, index, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Return thresholded img where is only 0s and 1s without probabilities\n",
    "        \"\"\"\n",
    "        thresholded_img = (self.predictions[index] > threshold).astype(np.uint8)\n",
    "        thresholded_img[thresholded_img == 1] = 255\n",
    "        return thresholded_img\n",
    "\n",
    "    def display_raw_probabilities_mask(self, index):\n",
    "        \"\"\"\n",
    "        Draw predicted probabilities of the model (without any thresholding).\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.axis(\"Off\")\n",
    "        plt.imshow(self.predictions[index])\n",
    "\n",
    "    def display_original_img_vs_raw_prediction(self, index):\n",
    "        \"\"\"\n",
    "        Draw image - prediction probability pair. \n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('Image', fontweight='bold', fontsize=30)\n",
    "        plt.axis(\"Off\")\n",
    "        plt.imshow(self.images[index])\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title(\"Predicted probabily mask\",fontweight='bold', fontsize=30)\n",
    "        plt.axis(\"Off\")\n",
    "        plt.imshow(self.predictions[index])\n",
    "\n",
    "    def iou_for_one_image(self, index):\n",
    "        intersection = np.logical_and(self.ground_truth[index], self.predictions[index])\n",
    "        union = np.logical_or(self.ground_truth[index], self.predictions[index])\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        return iou_score\n",
    "    \n",
    "    def iou_score(self):\n",
    "        iou = 0\n",
    "        for i in range(len(self.predictions)):\n",
    "            iou += iou_for_one_image(i)\n",
    "        return iou / len(self.predictions)\n",
    "\n",
    "    \n",
    "class SigmoidMulticalssModelEvaluation(SigmoidEvaluator):\n",
    "    \n",
    "    def __init__(self, prediction_dict_path, best_threshold=0.5):\n",
    "        SigmoidEvaluator.__init__(self, prediction_dict_path, best_threshold)\n",
    "        \n",
    "\n",
    "class SigmoidOneClassModelEvaluation(SigmoidEvaluator):\n",
    "    \n",
    "    def __init__(self, prediction_dict_path, best_threshold=0.5):\n",
    "        SigmoidEvaluator.__init__(self, prediction_dict_path, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxEvaluator(BaseEvaluator):\n",
    "    \n",
    "    def __init__(self, prediction_dict_path):\n",
    "        BaseEvaluator.__init__(self,prediction_dict_path)\n",
    "        self.performanceMetrics = PerformanceMetrics()\n",
    "#         self.doctors_predict = float(self.dict_of_prediction_data['name_of_the_dataset'].split('_')[1]) / 100\n",
    "        self.doctors_predict = procento.loc[int(self.dict_of_prediction_data['name_of_the_dataset'])]['procento_stenozy'] / 100\n",
    "    def get_mask(self, index):\n",
    "        return np.copy(self.ground_truth[index])\n",
    "    \n",
    "    def get_prediction(self, index):\n",
    "        return np.copy(self.predictions[index])\n",
    "    \n",
    "    def get_image(self, index):\n",
    "        return np.copy(self.images[index])\n",
    "    \n",
    "    def collapse_mask(self, index, isGroundTruth=False):\n",
    "        \"\"\"\n",
    "        Apply np.argmax function to the prediction mask to get 1-D image. \n",
    "        \"\"\"\n",
    "        if isGroundTruth:\n",
    "            return np.argmax(self.ground_truth[index], axis=-1)\n",
    "        return np.argmax(self.predictions[index], axis=-1)\n",
    "        \n",
    "    def prepare_mask_for_display(self, index, isGroundTruth=False):\n",
    "        if isGroundTruth:\n",
    "            collapsed_prediction = self.collapse_mask(index, isGroundTruth)\n",
    "        else:\n",
    "            collapsed_prediction = self.collapse_mask(index)\n",
    "        collapsed_prediction+=1 # moving class index from 0 to 1 for making so that tisssue=1, lumen=2, artifacts=3\n",
    "        collapsed_prediction[collapsed_prediction==4] = 0 # making background as a 0 class\n",
    "        return collapsed_prediction\n",
    "\n",
    "    def mean_iou_per_image(self, index):\n",
    "        return self.performanceMetrics.mean_IU(self.prepare_mask_for_display(index),\n",
    "                                               self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "                                              )\n",
    "    \n",
    "    def pixel_accuracy_per_image(self, index):\n",
    "        return self.performanceMetrics.pixel_accuracy(self.prepare_mask_for_display(index),\n",
    "                                                      self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "                                                     )\n",
    "    \n",
    "    def mean_accuracy_per_image(self, index):\n",
    "        return self.performanceMetrics.mean_accuracy(self.prepare_mask_for_display(index),\n",
    "                                                     self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "                                                    )\n",
    "    \n",
    "    def frequency_weighted_iou_per_image(self, index):\n",
    "        return self.performanceMetrics.frequency_weighted_IU(self.prepare_mask_for_display(index),\n",
    "                                                             self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "                                                            )\n",
    "    \n",
    "    def _calulate_metric_over_all_test_set(self, metric_function):\n",
    "        \"\"\"\n",
    "        Return calculated metric of a given function over all test set.\n",
    "        \"\"\"\n",
    "        iou = 0\n",
    "        for i in range(self.number_of_test_images):\n",
    "            iou+= metric_function(i)\n",
    "        iou /= self.number_of_test_images\n",
    "        return iou\n",
    "    \n",
    "    def get_mean_iou(self):\n",
    "        \"\"\"\n",
    "        Return Mean IoU of all test set. \n",
    "        \"\"\"\n",
    "        return self._calulate_metric_over_all_test_set(self.mean_iou_per_image)\n",
    "    \n",
    "    def get_pixel_accuracy(self):\n",
    "        \"\"\"\n",
    "        Return Pixel Accuracy of all test set. \n",
    "        \"\"\"\n",
    "        return self._calulate_metric_over_all_test_set(self.pixel_accuracy_per_image)\n",
    "    \n",
    "    def get_mean_accuracy(self):\n",
    "        \"\"\"\n",
    "        Return Mean Accuracy of all test set.\n",
    "        \"\"\"\n",
    "        return self._calulate_metric_over_all_test_set(self.mean_accuracy_per_image)\n",
    "    \n",
    "    def get_frequency_weighted_iou(self):\n",
    "        \"\"\"\n",
    "        Return Frequency Weighted IoU of all test set.\n",
    "        \"\"\"\n",
    "        return self._calulate_metric_over_all_test_set(self.frequency_weighted_iou_per_image)\n",
    "    \n",
    "    def get_evaluation(self):\n",
    "        evaluation_metrics = {}\n",
    "        evaluation_metrics['Frequency weighted IoU'] = self.get_frequency_weighted_iou()\n",
    "        evaluation_metrics['Mean IoU'] = self.get_mean_iou()\n",
    "        evaluation_metrics['Mean Accuracy'] = self.get_mean_accuracy()\n",
    "        evaluation_metrics['Pixel Accuracy'] = self.get_pixel_accuracy()\n",
    "        return evaluation_metrics\n",
    "    \n",
    "    def display_mask(self, index):\n",
    "        prepared_mask = self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(prepared_mask, cmap='seismic')\n",
    "        \n",
    "    def display_prediction(self, index):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(prepared_prediction, cmap='seismic')\n",
    "        \n",
    "    def display_prediction_mask_pair(self, index):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        prepared_mask = self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('Ground Truth', fontweight='bold', fontsize=30)\n",
    "        plt.imshow(prepared_mask, cmap='seismic')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('Prediction', fontweight='bold', fontsize=30)\n",
    "        plt.imshow(prepared_prediction, cmap='seismic')\n",
    "    \n",
    "    def display_original_img_prediction_pair(self, index):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('Original Image', fontweight='bold', fontsize=30)\n",
    "        plt.imshow(self.images[index])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('Prediction', fontweight='bold', fontsize=30)\n",
    "        plt.imshow(prepared_prediction, cmap='seismic')\n",
    "    \n",
    "    def display_mask_prediction(self, index):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        lumen = np.copy(prepared_prediction)\n",
    "        lumen[lumen!=2] = 0\n",
    "        lumen[lumen==2] = 255\n",
    "\n",
    "        artifacts = np.copy(prepared_prediction)\n",
    "        artifacts[artifacts!=3] = 0\n",
    "        artifacts[artifacts==3] = 255\n",
    "\n",
    "        tissue = np.copy(prepared_prediction)\n",
    "        tissue[tissue!=1] = 0\n",
    "        tissue[tissue==1] = 255\n",
    "        \n",
    "        prepared_mask = self.prepare_mask_for_display(index, isGroundTruth=True)\n",
    "        lumen_mask = np.copy(prepared_mask)\n",
    "        lumen_mask[lumen_mask!=2] = 0\n",
    "        lumen_mask[lumen_mask==2] = 255\n",
    "\n",
    "        artifacts_mask = np.copy(prepared_mask)\n",
    "        artifacts_mask[artifacts_mask!=3] = 0\n",
    "        artifacts_mask[artifacts_mask==3] = 255\n",
    "\n",
    "        tissue_mask = np.copy(prepared_mask)\n",
    "        tissue_mask[tissue_mask!=1] = 0\n",
    "        tissue_mask[tissue_mask==1] = 255\n",
    "        \n",
    "        final_mask = np.dstack((tissue, lumen, artifacts)).astype(np.uint8)\n",
    "        \n",
    "        _, tissue_countours, _ = cv.findContours(tissue_mask.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, artifact_countours, _ = cv.findContours(artifacts_mask.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, lumen_countours, _ = cv.findContours(lumen_mask.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "        cv.drawContours(final_mask, tissue_countours, -1, (255,180,180), 2)\n",
    "        cv.drawContours(final_mask, lumen_countours, -1, (180,255,180), 2)\n",
    "        cv.drawContours(final_mask, artifact_countours, -1, (180,180,255), 2)\n",
    "        return final_mask\n",
    "    \n",
    "    def display_merged_img_prediction(self, index, intensity=0.1):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        lumen = np.copy(prepared_prediction)\n",
    "        lumen[lumen!=2] = 0\n",
    "        lumen[lumen==2] = 255\n",
    "\n",
    "        artifacts = np.copy(prepared_prediction)\n",
    "        artifacts[artifacts!=3] = 0\n",
    "        artifacts[artifacts==3] = 255\n",
    "\n",
    "        tissue = np.copy(prepared_prediction)\n",
    "        tissue[tissue!=1] = 0\n",
    "        tissue[tissue==1] = 255\n",
    "\n",
    "        final_mask = np.dstack((tissue, lumen, artifacts)).astype(np.uint8)\n",
    "        _, tissue_countours, _ = cv.findContours(tissue.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, artifact_countours, _ = cv.findContours(artifacts.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, lumen_countours, _ = cv.findContours(lumen.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        final_mask = cv.addWeighted(np.copy(self.images[index]),1,final_mask,intensity, 0)\n",
    "        cv.drawContours(final_mask, tissue_countours, -1, (255,0,0), 1)\n",
    "        cv.drawContours(final_mask, lumen_countours, -1, (0,255,0), 1)\n",
    "        cv.drawContours(final_mask, artifact_countours, -1, (0,0,255), 1)\n",
    "#                 plt.figure(figsize=(10,10))\n",
    "#         plt.imshow(cv.addWeighted(a.images[index],1,final_mask,intensity, 0))\n",
    "        return final_mask\n",
    "\n",
    "    def _helper_process_patient(self, index, intensity=0.1):\n",
    "        prepared_prediction = self.prepare_mask_for_display(index)\n",
    "        lumen = np.copy(prepared_prediction)\n",
    "        lumen[lumen!=2] = 0\n",
    "        lumen[lumen==2] = 255\n",
    "\n",
    "        artifacts = np.copy(prepared_prediction)\n",
    "        artifacts[artifacts!=3] = 0\n",
    "        artifacts[artifacts==3] = 255\n",
    "\n",
    "        tissue = np.copy(prepared_prediction)\n",
    "        tissue[tissue!=1] = 0\n",
    "        tissue[tissue==1] = 255\n",
    "\n",
    "        final_mask = np.dstack((tissue, lumen, artifacts)).astype(np.uint8)\n",
    "        _, tissue_countours, _ = cv.findContours(tissue.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, artifact_countours, _ = cv.findContours(artifacts.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        _, lumen_countours, _ = cv.findContours(lumen.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        final_mask = cv.addWeighted(np.copy(self.images[index]),1,final_mask,intensity, 0)\n",
    "        cv.drawContours(final_mask, tissue_countours, -1, (255,0,0), 1)\n",
    "        cv.drawContours(final_mask, lumen_countours, -1, (0,255,0), 1)\n",
    "        cv.drawContours(final_mask, artifact_countours, -1, (0,0,255), 1)\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        if (np.count_nonzero(tissue) + np.count_nonzero(lumen)) == 0:\n",
    "            percentage_stenosis = 1.0\n",
    "            cv.putText(final_mask,\"Hard to segment\",(10,50),font, 1,(255,255,255),2,cv.LINE_AA)\n",
    "        else:\n",
    "            percentage_stenosis = (np.count_nonzero(tissue) / (np.count_nonzero(tissue) + np.count_nonzero(lumen)))\n",
    "            if percentage_stenosis >=0.99:\n",
    "                cv.putText(final_mask,\"Hard to segment\",(10,50),font, 1,(255,255,255),2,cv.LINE_AA)\n",
    "            else:\n",
    "                cv.putText(final_mask,\"Percentage of stenosis: \"+str(np.round(percentage_stenosis,2)),(10,50), \n",
    "                           font, 1,(255,255,255),2,cv.LINE_AA)\n",
    "                cv.putText(final_mask,\"Your estimation: \"+str(self.doctors_predict),(10,100), \n",
    "                           font, 1,(50,255,50),2,cv.LINE_AA)\n",
    "        orig_img = my_eval.get_image(index)\n",
    "        cv.putText(orig_img,\"Original Image\",(10,50), font, 1,(255,255,255),2,cv.LINE_AA)\n",
    "        return (percentage_stenosis,final_mask, orig_img)\n",
    "    \n",
    "    def process_patient(self):\n",
    "        results = []\n",
    "        for i in range(self.number_of_test_images):\n",
    "            results.append(self._helper_process_patient(i))\n",
    "        \n",
    "        percentages_stenosis = [x[0] for x in results if x[0] < 0.99]\n",
    "        hard_to_segment = [x[1:] for x in results if x[0] >0.99]\n",
    "        norm_to_segmnet = [x[1:] for x in results if x[0]<=0.99]\n",
    "        \n",
    "        return (percentages_stenosis, hard_to_segment, norm_to_segmnet)\n",
    "\n",
    "def concat_images(imga, imgb):\n",
    "    \"\"\"\n",
    "    Combines two color image ndarrays side-by-side.\n",
    "    \"\"\"\n",
    "    ha,wa = imga.shape[:2]\n",
    "    hb,wb = imgb.shape[:2]\n",
    "    max_height = np.max([ha, hb])\n",
    "    total_width = wa+wb\n",
    "    new_img = np.zeros(shape=(max_height, total_width, 3))\n",
    "    new_img[:ha,:wa]=imga\n",
    "    new_img[:hb,wa:wa+wb]=imgb\n",
    "    return new_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_SAVE = '/home/bohdan/ultrasound/patients/'\n",
    "PREDICTION_DICT_PATH = '/home/bohdan/ultrasound/predictions/patients/'\n",
    "datasets_names = os.listdir(PREDICTION_DICT_PATH)\n",
    "datasets_names = [x.split('.')[0] for x in datasets_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TABLE = '/home/bohdan/Desktop/platy.xlsx'\n",
    "platy = pd.read_excel(PATH_TO_TABLE)\n",
    "procento = platy[['id','procento_stenozy']]\n",
    "procento = procento[np.logical_not(pd.isnull(procento['procento_stenozy']))]\n",
    "\n",
    "for i in procento.index:\n",
    "    if not isinstance(procento.loc[i]['procento_stenozy'], int):\n",
    "        procento.drop(i, inplace=True)\n",
    "\n",
    "procento.set_index(procento['id'], inplace=True)\n",
    "procento.drop('id', axis=1, inplace=True)\n",
    "procento.drop([452770,921310], inplace=True)# don`t have the ultrasound data\n",
    "procento.drop([220574,890878], inplace=True) # bad quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_stenosis_perscntage(my_eval, percentages_stenosis, path_to_save):\n",
    "    f = plt.figure(figsize=(25,10))\n",
    "    ax = f.add_subplot(111)\n",
    "\n",
    "    plt.xlabel('Images', fontweight='bold',fontsize=20)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    plt.title(\"Patient ID: {}\".format(my_eval.dict_of_prediction_data['name_of_the_dataset']),\n",
    "              fontweight='bold',fontsize=30)\n",
    "    \n",
    "    xt = ax.get_yticks() \n",
    "    xt=np.append(xt, my_eval.doctors_predict)\n",
    "    xtl=xt.tolist()\n",
    "    xtl = [np.round(x,1) for x in xtl]\n",
    "    xtl[-1]=\"Your Percentage of stenosis: {}\".format(str(my_eval.doctors_predict))\n",
    "    ax.set_yticks(xt)\n",
    "    ax.set_yticklabels(xtl)\n",
    "\n",
    "    plt.ylim((0,1.1))\n",
    "    plt.plot(percentages_stenosis,marker='o', color='blue', linewidth=5, alpha=0.7, markersize=15)\n",
    "    plt.axhline(y=my_eval.doctors_predict, ls=\"--\", c=\"red\", linewidth=3)\n",
    "    plt.savefig(path_to_save)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e7aecbd1c047e69da3b0600f654261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=111), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hard_to_interpret = {}\n",
    "persentages_of_stenosys_of_all_patients = {}\n",
    "for i in tqdm_notebook(range(len(datasets_names))):\n",
    "    my_eval = SoftmaxEvaluator(\n",
    "        PREDICTION_DICT_PATH+datasets_names[i]+'.dat'\n",
    "    )\n",
    "    percentages_stenosis, hard_to_segment, norm_to_segment = my_eval.process_patient()\n",
    "    hard_to_interpret[my_eval.dict_of_prediction_data['name_of_the_dataset']] = hard_to_segment\n",
    "    \n",
    "    path_for_new_patient = os.path.join(PATH_TO_SAVE,datasets_names[i])\n",
    "    if not os.path.exists(path_for_new_patient):\n",
    "        os.mkdir(path_for_new_patient)\n",
    "    \n",
    "    segmentation_path = os.path.join(path_for_new_patient, 'segmentation_results')\n",
    "    if not os.path.exists(segmentation_path):\n",
    "        os.mkdir(segmentation_path)\n",
    "    \n",
    "    path_to_save_figure=path_for_new_patient+'/'+datasets_names[i]+'.png'\n",
    "    plot_patient_stenosis_perscntage(my_eval, percentages_stenosis, path_to_save_figure)\n",
    "    \n",
    "    persentages_of_stenosys_of_all_patients[my_eval.dict_of_prediction_data['name_of_the_dataset']] = percentages_stenosis\n",
    "    \n",
    "    for j in range(len(norm_to_segment)):\n",
    "        norm_to_segment_result = norm_to_segment[j][0]\n",
    "        norm_to_segment_original = norm_to_segment[j][1]\n",
    "        merged_img = concat_images(norm_to_segment_original[..., ::-1],norm_to_segment_result[..., ::-1])\n",
    "        cv.imwrite(segmentation_path+'/'+str(j)+'.png',merged_img)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.439723887675903\n"
     ]
    }
   ],
   "source": [
    "whole_error = 0\n",
    "for i in range(len(procento)):\n",
    "    right_prediction = (procento.loc[int(datasets_names[i])] / 100)['procento_stenozy']\n",
    "    our_prediction = persentages_of_stenosys_of_all_patients[datasets_names[i]]\n",
    "    our_prediction.sort()\n",
    "    \n",
    "    if len(our_prediction) == 0:\n",
    "#             print(datasets_names[i])\n",
    "            continue\n",
    "    elif len(our_prediction) <= 3:\n",
    "        our_prediction = np.mean(our_prediction)\n",
    "    else:\n",
    "        our_prediction = np.mean(our_prediction[:4])\n",
    "    whole_error+= abs(our_prediction - right_prediction)\n",
    "#     print(datasets_names[i],\": \",right_prediction, ' ', our_prediction, len(persentages_of_stenosys_of_all_patients[datasets_names[i]]))\n",
    "print(whole_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_percentage_of_stenosis = []\n",
    "our_percentage_of_stenosis = []\n",
    "indexes_to_remove = []\n",
    "for i in range(len(procento)):\n",
    "    right_prediction = (procento.loc[int(datasets_names[i])] / 100)['procento_stenozy']\n",
    "    our_prediction = persentages_of_stenosys_of_all_patients[datasets_names[i]]\n",
    "    our_prediction.sort()\n",
    "    \n",
    "    if len(our_prediction) == 0:\n",
    "            indexes_to_remove.append(datasets_names[i])\n",
    "            continue\n",
    "    elif len(our_prediction) <= 3:\n",
    "        our_prediction = np.mean(our_prediction)\n",
    "    else:\n",
    "        our_prediction = np.mean(our_prediction[:4])\n",
    "    our_percentage_of_stenosis.append(our_prediction)\n",
    "    your_percentage_of_stenosis.append(right_prediction)\n",
    "#     print(datasets_names[i],\": \",right_prediction, ' ', our_prediction, len(persentages_of_stenosys_of_all_patients[datasets_names[i]]))\n",
    "indexes_to_remove = [int(x) for x in indexes_to_remove]\n",
    "our_percentage_of_stenosis = [np.round(x, 2)*100 for x in our_percentage_of_stenosis]\n",
    "your_percentage_of_stenosis = [int(x*100) for x in your_percentage_of_stenosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Your Percentage of Stenosis</th>\n",
       "      <th>Our Percentage of Stenosis</th>\n",
       "      <th>Our Comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PatientID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105520</th>\n",
       "      <td>65</td>\n",
       "      <td>65.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128207</th>\n",
       "      <td>30</td>\n",
       "      <td>90.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131283</th>\n",
       "      <td>70</td>\n",
       "      <td>88.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137930</th>\n",
       "      <td>50</td>\n",
       "      <td>63.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144329</th>\n",
       "      <td>75</td>\n",
       "      <td>83.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Your Percentage of Stenosis  Our Percentage of Stenosis  \\\n",
       "PatientID                                                            \n",
       "105520                              65                        65.0   \n",
       "128207                              30                        90.0   \n",
       "131283                              70                        88.0   \n",
       "137930                              50                        63.0   \n",
       "144329                              75                        83.0   \n",
       "\n",
       "          Our Comments  \n",
       "PatientID               \n",
       "105520            None  \n",
       "128207            None  \n",
       "131283            None  \n",
       "137930            None  \n",
       "144329            None  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = procento.index\n",
    "indexes = [x for x in indexes if x not in indexes_to_remove]\n",
    "d = {\n",
    "    'Our Percentage of Stenosis': our_percentage_of_stenosis,\n",
    "    'Your Percentage of Stenosis': your_percentage_of_stenosis,\n",
    "    'Our Comments': [None for x in range(len(indexes)) ]\n",
    "}\n",
    "df = pd.DataFrame(\n",
    "    index= indexes,\n",
    "    data=d\n",
    ")\n",
    "df.index.name = \"PatientID\"\n",
    "columnsTitles = ['Your Percentage of Stenosis', 'Our Percentage of Stenosis','Our Comments']\n",
    "df = df.reindex(columns=columnsTitles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('procento_stenozy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(PATH_TO_SAVE, 'hard_to_segment')):\n",
    "    os.mkdir(os.path.join(PATH_TO_SAVE, 'hard_to_segment'))\n",
    "    \n",
    "for patient in hard_to_interpret:\n",
    "    if not os.path.exists(os.path.join(PATH_TO_SAVE,'hard_to_segment', patient)):\n",
    "        os.mkdir(os.path.join(PATH_TO_SAVE, 'hard_to_segment', patient))\n",
    "    \n",
    "    for i in range(len(hard_to_interpret[patient])):\n",
    "        merged_img = concat_images(hard_to_interpret[patient][i][1],hard_to_interpret[patient][i][0])[..., ::-1]\n",
    "        cv.imwrite(os.path.join(PATH_TO_SAVE, 'hard_to_segment', patient)+'/'+str(i)+'.png',merged_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results of concatenating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_concatenated_imgs(evaluator, path_to_save):\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.mkdir(path_to_save)\n",
    "    images_to_stack = []\n",
    "    for i in range(len(evaluator)):\n",
    "        prediction_mask = evaluator.display_mask_prediction(i)\n",
    "        original_prediction = evaluator.display_merged_img_prediction(i)\n",
    "        images_to_stack.append((original_prediction, prediction_mask))\n",
    "\n",
    "    for i in range(len(evaluator)):\n",
    "        im = concat_images(images_to_stack[i][0],images_to_stack[i][1])\n",
    "        cv.imwrite(os.path.join(path_to_save,'{}.png'.format(str(i))), im[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets_names:\n",
    "    my_eval = SoftmaxEvaluator(\n",
    "        PREDICTION_DICT_PATH+dataset_name\n",
    "    )\n",
    "    save_concatenated_imgs(my_eval,'/home/bohdan/ultrasound/predictions/model_estimation/{}/predictions/'\n",
    "                           .format(dataset_name.split('.')[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='BohdanPetryshak', api_key='h8ECd47FhDo1gfrRULQg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_acc = []\n",
    "mean_acc = []\n",
    "mean_iou = []\n",
    "for dataset_name in datasets_names:\n",
    "    my_eval = SoftmaxEvaluator(\n",
    "        PREDICTION_DICT_PATH+dataset_name\n",
    "    )\n",
    "    pixel_acc.append(my_eval.get_pixel_accuracy())\n",
    "    mean_acc.append(my_eval.get_mean_accuracy())\n",
    "    mean_iou.append(my_eval.get_mean_iou())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['rgb_color_aug.dat',\n",
    " 'rgb_non_rigid_aug.dat',\n",
    " 'rgb_color_non_destructive_aug.dat',\n",
    " 'rgb_all_types_of_aug.dat',\n",
    " 'rgb_non_destructive_aug.dat']\n",
    "lab = [0,0,0,0,0,1,1,1,1,1,2,2,2,2,2]\n",
    "metrics_names = ['Pixel Accuracy', 'Mean Accuracy', 'Mean IoU']\n",
    "data = pd.DataFrame({'acc': pixel_acc+mean_acc+mean_iou,\n",
    "                     'names': labels+labels+labels,\n",
    "                     'lab': [metrics_names[x] for x in lab]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.barplot(x=\"names\", y=\"acc\", data=data, hue='lab', palette=['#96bf80', '#6c8ebf', '#b85450'])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.plot(secondary_y=['B'],grid=False)\n",
    "plt.xticks(rotation=10)# fontweight='bold')\n",
    "plt.yticks(fontweight='bold')\n",
    "plt.xticks(fontweight='bold')\n",
    "sns.set(style=\"whitegrid\",context='poster')\n",
    "plt.xlabel('Datasets \\n ', fontsize=30, fontweight='bold')\n",
    "plt.ylabel('IoU', fontsize=30, fontweight='bold')\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = my_eval.prepare_mask_for_display(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumen = np.copy(a)\n",
    "lumen[lumen!=2] = 0\n",
    "lumen[lumen==2] = 255\n",
    "\n",
    "artifacts = np.copy(a)\n",
    "artifacts[artifacts!=3] = 0\n",
    "artifacts[artifacts==3] = 255\n",
    "\n",
    "tissue = np.copy(a)\n",
    "tissue[tissue!=1] = 0\n",
    "tissue[tissue==1] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Pixel Accuracy', 'Mean Accuracy', 'Mean IoU']\n",
    "lab = [0,1,2,3,4,5,0,1,2,3,4,5,0,1,2,3,4,5]\n",
    "metrics_names = ['Color', 'Non-Rigid', \n",
    "                 'Color + Non-Destructive', \n",
    "                 'Color + Non-Rigid + Non-Destructive',\n",
    "                 'Non-Destructive', 'Without augmentation']\n",
    "data = pd.DataFrame({'acc': pixel_acc+mean_acc+mean_iou,\n",
    "                     'names': labels[:1]*6+labels[1:2]*6+labels[2:]*6,\n",
    "                     'lab': [metrics_names[x] for x in lab]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.barplot(x=\"names\", y=\"acc\", data=data, hue='lab')#, palette=['#96bf80', '#6c8ebf', '#b85450'])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylim((0.7,1))\n",
    "# ax.plot(secondary_y=['B'],grid=False)\n",
    "# plt.xticks(rotation=10)# fontweight='bold')\n",
    "plt.yticks(fontweight='bold')\n",
    "plt.xticks(fontweight='bold')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.xlabel('Performance Metrics \\n ', fontsize=30, fontweight='bold')\n",
    "plt.ylabel('IoU', fontsize=30, fontweight='bold')\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(1,100), (2,90), (3,80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinplot(flip=1):\n",
    "    x = np.linspace(0, 14, 100)\n",
    "    for i in range(1, 7):\n",
    "        plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(x, y)\n",
    "\n",
    "# Hide the right and top spines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
